2018-12-11

Postmortem #2

We came across more ideas that we have found flaws with.

Attempted approaches for (min, plus) or lax Boolean:

1. This strain of idea comes from 2016. At first, we notice that we have a kind of tree that could lead to better time for red-blue dominance pair reporting -- this turns out to be false because we we have a coefficient of d that is not low and fixed but in O(n); this makes our approach take more than in O(n ^ 2 * polylog(n)) and in big-Omega of n ^ 3. The details follow. The red-blue dominance pair reporting is a task described by Chan 2008 for purpose of solving (min, plus) MM. Then, we can reduce both lax Boolean MM and all-pairs shortest paths (APSP) to (min, plus) MM. Lax Boolean MM is case where input values are in {0, 1} and we have semiring of (OR, AND). For contrast, strict Boolean MM is case whre input values are in {0, 1} and we have ring of (plus, times). The trees we use are specifically are a pair of R-trees with sort-tile-recursive-based (i.e STR-based) bulk-loading with round-robin dimension changing (see Leutenegger 1997). We choose to use R-tree (instead of e.g. k-d tree) because we make use of bounding boxes and we do not clone stored items (i.e. points for our application) -- though, we note that with k-d tree we do not clone primitives either. For the most part, we are disjoint for our bounding boxes for a particular node's children, but we may have ties at shared border of two bounding boxes (i.e. assuming our branching factor is two). The two trees are balanced at the expense of separating ties into left and right children inconsistently. For each node, we know based on query point immediately (i.e after O(d) time for edge checks) that a certain child is s.t. if we enter associated subtree that we will get a match. For the other child, we use "look-ahead" to determine whether to enter that other subtree; this makes a query more expensive by increasing time coefficient for number of pairs reported by a factor of O(log(n)) to be O(log(n) ^ 2). Time required for overall red-blue dominance pair reporting is in O(d * n ^ 2 * log(n) ^ 2). For low and fixed d, this time is less than cubic in n. For d = O(n), which is what we require for square (min, plus) or lax Boolean MM problems, the time for this task is O(n ^ 3 * log(n) ^ 2) -- i.e. more than cubic in n; as this is more expensive than brute force, the approach is not an improvement. There are more details. We use corner transformation (i.e. see Pagel 1993) for d-dimensional rectangles to turn them into points with 2 * d dimensions. The pair of trees is used for dominance queries. Chan guarantees that after all necessary queries that we have exactly n ^ 2 reported pairs. We use red-blue-dominance-min-sum-pair arithmetic -- i.e. we re-write min. of sum pairs problem as a problem about being dominated over all components with transform to turn a O(2 * d)-length vector into an O(2 * d - 1)-length vector. We note that each of these reductions (i.e. from lax Boolean MM or APSP to (min, plus) MM) does not increase the asymptotic time required. The re-writing is reminiscent of using union-intersection arithmetic for strict Boolean MM as from Kaplan 2008 -- i.e. there we re-write Boolean intersection (i.e. AND) problem as a problem about Boolean union (i.e. OR).

2. Cohen/Porat 2010 talk about reducing lax Boolean MM to approximate APSP for graph s.t. multiplicative error is constant (i.e. at most two) and additive error is constant and low. At first glance, Johnson-Lindenstrauss lemma seems appropriate but the associated transform is Monte-Carlo. Then, a paper from Henzinger 2018 seems to give an appropriate (1 - epsilon) multiplicative error and zero additive error approach. We are not sure if the provided algorithm is exactly enough and the suggested approach seems to be quite involved, as well.

3. Roditty/Zwick 2004 talk about reducing lax Boolean MM to SSSP in decremental setting. This configuration also reminds us of our hot-dog pair point arrangement with closest pair range query with critical min. distance for (min, plus) MM -- it is clever. In fact, we adapt their node configuration for use with a max. flow algorithm that we hope will work for determining not just whether there is a shortest path that signifies a one as value for an output for lax Boolean MM, but to count number of shortest paths for strict Boolean MM. We may have more to say about this in the future, elsewhere.

Attempted approaches for (plus, times) for strict Boolean:

1. Rewriting using rectangles. We re-write vectors to be sums of weighted rectangles (i.e. we have weights for groups of adjacent offsets in input vectors -- whether for A row or B column -- we note also that each offset we refer to as a "color") s.t. for each vector we have a number of rectangles sublinear in n. There seems to be no reason to believe that the following would occur at worst: number of reference vectors sublinear in n, number of non-zeroes for each reference vector sublinear in n, number of non-zeroes for each output vector sublinear in n. We also assume we have a a fast transform. For example, we know via discrete Fourier transform that we have a change of basis. No vectors in the basis are redundant by definition of basis -- we are a minimal spanning set. Let us assume we are using a Walsh-Hadamard transform so that values in reference vectors are negative one or positive one. For it we have O(n * log(n)) time for transform. We empirically at worst have O(n) reference vectors, O(n) number of non-zeroes for an reference vector, O(n) number of non-zeroes for an output vector. Given that we are minimal, for what reason would we believe that we can at worst arrive at significant amount of work saved via a separate change of basis? We are considering work saved in form of reference vector number of non-zeroes and output vector number of non-zeroes. Finally, we have no reason to believe that at worst l1-norm distance between input vectors pair-wise, reference vectors pair-wise, output vectors pair-wise are not all still in O(n) via separate nearest neighbor considerations from a prior postmortem, as well. As a reminder, for that aspect, we consider packing of n-dimensional "primary" hypercube surface using n (n - 1)-dimensional "primitive" hypercube volumes.

Miscellany:

1. Another problem that we are interested in pursuing is transitive reduction of a DAG, which is reduceable to lax Boolean MM, which (again) is reduceable to (min, plus) MM. An interesting note is that Fischer/Meyer 1971 show for the other direction that lax Boolean MM is efficiently reduceable to transitive closure (which in turn is related to transitive reduction). This reduction shows that as an approach for lax Boolean MM with significantly-subcubic-time is unlikely, we are unlikely to achieve such a time for transitive reduction, as well. As a result, we a moderately satisfied with an algorithm for transitive reduction that already exists and that takes advantage of sparsity and at worst takes time in O(|V| * |E|) = O(n ^ 3).

2. We wish to pursue diversity of MM problems -- e.g. (max, min) for all-pairs bottleneck paths or (min, plus) for all-pairs shortest paths. We do so because our (plus, times) approaches will be even more restrictive than (plus, times) for Strassen-likes, given that we are not able to swap out specific rings. These semi-rings are not directly supported by our approach or Strassen-likes. In short, we wish to show that we can support specific semi-rings to compensate for our decision to make a trade-off between brittleness and progress for the most commonly used rings (e.g. for zero-one, integer, f.p.). Note that by zero-one we mean strict Boolean.

3. Williams 2014 mentions reducing graph "diameter" to APSP. We thought initially that they claim a reduction in the other direction, which they do not. Further, by diameter they mean largest path distance between a pair of vertices in a graph. They do not mean range diameter query -- i.e. largest distance between a pair of points in a range. We care about the latter because it is close to closest pair range query with critical min. distance in that there is tension -- though they are arguably quite different, the idea is that we may be able to adapt, given that it is important that the main query algorithm we use should primarily exist and secondarily have good time/space characteristics.

References

* Chan - All-pairs shortest paths with real weights in O(n ^ 3 / log(n)) time (2008)
* Kaplan et al. - Efficient colored orthogonal range counting (2008)
* Pagel et al. - The transformation technique for spatial objects revisited (1993)
* Leutenegger et al. - STR: A simple and efficient algorithm for R-tree packing (1997)
* Fischer, Meyer - Boolean matrix multiplication and transitive closure (1971)
* Cohen and Porat - On the hardness of distance oracle for sparse graph (2010)
* Williams et al. - Subcubic equivalences between graph centrality problems, APSP and diameter (2014)
* Roditty and Zwick - On dynamic shortest paths problems (2004)
* Henzinger et al. - Decremental single-source shortest paths on undirected graphs in near-linear total update time (2018)

--


