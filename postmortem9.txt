2019-10-13

POSTMORTEM #9

We have a few leads that we ended up scorning.

1. Tau significant-presence query from de Berg and Haverkort 2003.

The de Berg and Haverkort 2003 paper provides good time for exact and approximate significant-presence queries for case of one dimension; those times are independent of tau and epsilon. Why do we care about approximate case if exact case has same time? If we wish to support variable tau, non-zero epsilon is effectively required (unless we want a prohibitively large number of fixed-tau trees).

Let us first consider 2-d case. There is a problem because the values we choose for tau and epsilon affect the time unforgivingly. For approximate 2-d case, number of boxes for a single color is proportional to 1 / (tau ^ 2) and proportional to 1 / (epsilon ^ 3). If we can set epsilon to a constant and tau in O(1 / sqrt(n)) and we have n colors, then number of test boxes for all colors together is in O(n ^ 2). We use a descending staircase pair as from Kaplan et al. A well-formed query is a 2-d rectangle that includes one A vector (i.e. one point location from left staircase) and one B vector (i.e. one point location from right staircase). Also, if we imagine w.r.t. origin that left staircase fits entirely in quadrant III and right staircase fits entirely in quadrant I, we can have a point for each color at origin that will always fit in a well-formed query. We might also wish to have a landfill point at an extreme location s.t. no well-formed query will ever include it in its range. We can support non-negative (without loss of generality integer) weights for points with the de Berg and Haverkort 2003 algorithms given that these weights can be viewed as clones of points that have unit weight that are (crucially) all at same location; i.e. we support these weighted points without changing time required for the text box creation. We have a trick that we use to avoid numerical robustness issues; we store the numerator of a tau so that we use integers instead of possibly imprecise floating-point fractions. Tau will be tiny and expensive unless we weight the origin point for each color by e.g. n instead of one; then tau can be slightly larger than 0.5. In this case, then 1 - epsilon is tau_0 / tau_1 s.t. tau_1 is fraction for a fixed color s.t. we see two one bits out of 2 * n one bits (or 4 * n if we have weighting at origin of n) and s.t. tau_0 is fraction for a fixed color s.t. we see at most one one bit out of 2 * n one bits (or 4 * n, again). If we have weighting using n at origin, this fraction is [(1 + 2 * n) / (4 * n)] / [(2 + 2 * n) / (4 * n)] = (1 + 2 * n) / (2 + 2 * n); solving for epsilon, we get epsilon in O(1 / (2 * (n + 1))) = O(1 / n) (which is too large). Alternatively, if we have no origin points, this fraction is [1 / (2 * n)] / [2 / (2 * n)] = 1 / 2; solving for epsilon, we get epsilon equal to 0.5 (which is small); then, tau is in 2 / (2 * n) = O(1 / n), which is too expensive. If we work out the parameter values tau and epsilon for when we weight using n ^ p where p is a parameter greater than or equal to one, we get the same behavior as what happens when p is one (as we described above). If p == 0.5, 1 - epsilon is [(1 + sqrt(n)) / (2 * n + sqrt(n))] / [(2 + sqrt(n)) / (2 * n + sqrt(n))] = (1 + sqrt(n)) / (2 + sqrt(n)); solving for epsilon, we get epsilon in 1 / (sqrt(n) + 2) = O(1 / sqrt(n)). For this same case, tau is in O(1 / sqrt(n)). Then (again assuming p == 0.5), number of approximate test boxes for a fixed color is proportional to O(1 / (tau ^ 2 * epsilon ^ 3)) = O(n * n * sqrt(n)), which means overall time in O(n ^ 3 * sqrt(n)), which is too much. We note that exact test boxes for dimension greater than or equal to two require for a single color (as the authors mention in their article) space at least cubic in n. Finally, we note that denominator is always 2 * n or 4 * n (for case where we have no origin points or we have origin points weighted using n, respectively); this we do even though we omit points for A vector or B vector for a given offset if for that offset we have a zero bit. We are able to do this by using points with weight equal to the number of zero bits for a given color from any A vector or B vector that are far to a side that we call "landfill". We note that for 1-d case, we do not even have to include the landfill points as part of constructing exact/approximate test sets.

Then, let us consider 1-d case. We assume we are using projection of 2-d staircase pair with no origin point and with a landfill point onto x axis. Also, we introduce neutralizer points that each are weighted one if we have a zero bit for an A vector or for a B vector and that are weighted zero if we have one bit for such a vector; these points are placed to be more extremal than and adjacent to the point they are paired with w.r.t. origin. We note that for 1-d exact case, tau and epsilon do not affect time s.t. it is super-linear in n; we can then affordably make tau and epsilon tiny s.t. if we had 2-d approach it would be too expensive. However, we will need variable tau. We can let base tau be in O(1 / n); number of clones is proportional to log(1 / tau_base) = O(log(n)). However, number of clones is also proportional to 1 / log(1 + epsilon / 2). If we have even spacing (i.e. all left staircase or right staircase points are weighted the same -- e.g. one), epsilon is fine if we pick a close pair of A vector and B vector (e.g. A vector farthest to right and B vector farthest to left). In that case, it's 1 - 1 / 2 = 0.5. However, if we then choose a pair that is far (e.g. A vector farthest to left and B vector farthest to right), 1 - epsilon is tau_0 / tau_1 = [(1 + 2 * (n - 1)) / (2 * n)] / [(2 + 2 * (n - 1)) / (2 * n)] = [(2 * n) / (2 * n)] / [(2 * n + 1) / (2 * n)] = (2 * n) / (2 * n + 1); epsilon is 1 - [(2 * n) / (2 * n + 1)] = (2 * n + 1 - 2 * n) / (2 * n + 1) = 1 / (2 * n + 1) = O(1 / n). If epsilon is in O(1 / n), factor 1 / log(1 + epsilon / 2) is in big-theta of O(n); this is too much. If we choose uneven spacing (e.g. by starting at weight one close to center and increase weights by factor of two as we move outwards horizontally), we get good epsilon (i.e. a constant) if we choose a symmetric pair (i.e. an A vector that is as far from origin horizontally as the B vector is), but not if e.g. the B vector is much closer to origin horizontally. This is because moving the B vector to a neighbor B vector has a comparatively smaller associated change in weighted frequency. In other words, e.g. we take leftmost A vector and leftmost B vector. Total weight for a fixed color is 2 * (2 ^ n - 1). Epsilon is (choosing arbitrarily that the more indetectable change -- zero bit from B vector instead of zero bit from A vector -- is used for tau_0) s.t. 1 - epsilon = tau_0 / tau_1 = [[(2 ^ n) / [2 * (2 ^ n - 1)]] / [(2 ^ n + 1) / [2 * (2 ^ n - 1)]]] = (2 ^ n) / (2 ^ n + 1). This means epsilon is in O(1 / (2 ^ n + 1)), which is too expensive. We note that we have implemented 1-d exact approach using time linear in n. We get 1-d approximate approach (which the article does not explicitly describe) by using 1-d exact approach s.t. we replace tau with (1 - epsilon) * tau and round up to closest integer (assuming we use weights that are integers). Presumably if we do not use integer weights, we would not need to round. Also, we have neglected to mention that if we use powers of two for weights, we could end up using a lot of space or we have to be clever by only storing the power and not two raised to it; we need to perform arithmetic (e.g. summing) and we admit we have not fully figured out how to make thise efficient for large n (i.e. larger than size of a word).

A final note is that it is difficult to use negative weights; just because we contain a box with target weight that is high enough does not mean that we should report that color, because when a test box is in a query range, there could be a negative weight point outside of that test box that disqualifies that test box. Also, we use a tree s.t. we add test box set for all colors into that one tree. If we use 1-d case, we can use 2-d range tree, we turn test boxes into points of double dimension and we use orthant query. Also, we could use d-dimensional range minimum query with the points from Yuan/Atallah 2010 to have fast pre-processing time, space, query time -- this is s.t. we use 1-d test boxes and s.t. we instead of using 2-d range tree we use 2-d RMQ structure. It is important to note that we are using the RMQ structure to answer emptiness query and we have a 2-d grid (or "multi-dimensional array"). A pitfall for their structure is that number of items N = O(n ^ d) = O(n ^ 2) s.t. n is side length of an input square matrix (from our application) and d currently is two; if d >= 3, for example, space required for the RMQ structure is at least in O(n ^ 3). Also, we should note that it is not clear whether de Berg and Haverkort 2003 guarantee for variable tau that all colors with frequency at least (1 - epsilon * tau_curr) are reported; we just know that if we are reported that we are in that range. However, they do explicitly say that if a color exists with frequency at exactly or above the tau given for a query (assuming we use variable tau) that it will always be reported. Also, for our application even if we do not report all colors, if we are guaranteed to report a color with frequency at or above the target tau, this is good enough; also, if we instead of choosing such a color for our first report we report one in range of [(1 - epsilon) * tau_curr, 1] for frequency, this is good enough for us to stop after constant (i.e. one) report, as well (for our application).

2. We looked at alpha and beta majority queries. We refer to Wilkinson 2012. The problem with these is that for our application with two staircases is that if a color is to break out and be associated with a pair of matched one bits, alpha or beta will need to be in O(1 / n), which makes overall time for application of Boolean MM to be at least cubic in n.

3. Approximate range mode query from El-Zein et al. 2019. The problem with this is that it is for 3-sided planar query and it is approximate. We don't say that there is no way to use this approach, but there are two issues -- it is epsilon-approximate and it has three sides instead of four. Otherwise, it is very directly the problem for Boolean MM. The 3-sided aspect leads us to need to neutralize lack of one bit (i.e. we have a zero bit) by adding compensating one bits near their A vector or B vector bit partners as we grow a collection of A vectors and B vectors (instead of dealing with just a single A vector and B vector pair for a query range). The approximate aspect leads us to need to amplify the signal of paired one bits or else the times are too large; it is not clear how we would do so efficiently.

4. Approximate 2-D colored range counting from Rahul 2015. They at end of their article mention that they have left out pre-processing time details; in other words, pre-processing for their structure is too expensive currently.

5. Range closest pair for higher dimensions (i.e. d >= 3) from Chan et al. 2019. While their related work section mentions Xue's colored range closest pair (RCP) approaches (which have no fast pre-processing times yet), the actual article does not explicitly cover colored variant of RCP. That said, we mention this article because we had a reduction of colored 3-d RCP for our application as mentioned in previous postmortem to non-colored RCP; a flaw is that for dimension larger than two the time for orthogonal query is quite high. Specifically, we are not better than overall O-tilde(n ^ 3) for 3-d orthogonal query. O-tilde hides logarithmic factors.

--

References

* de Berg and Haverkort - Significant-presence range queries in categorical data (2003)
* El-Zein et al. - On approximate range mode and range selection (2019)
* Rahul - Approximate range counting revisited (2015)
* Wilkinson - Adaptive range counting and other frequency-based range query problems (2012)
* Yuan and Atallah 2010 - Data structures for range minimum queries in multidimensional arrays (2010)

--


